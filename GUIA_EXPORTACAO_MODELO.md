# ðŸ“˜ Guia: ExportaÃ§Ã£o de Modelo Machine Learning

## O que Ã© ExportaÃ§Ã£o de Modelo?

A **exportaÃ§Ã£o de modelo** Ã© o processo de salvar um modelo treinado em um arquivo para uso posterior, sem precisar retreinÃ¡-lo. Isso permite:

- âœ… Reutilizar o modelo em produÃ§Ã£o (APIs, apps)
- âœ… Compartilhar modelos com outras pessoas/sistemas
- âœ… Versionar modelos (controle de qualidade)
- âœ… Reduzir tempo de inicializaÃ§Ã£o (nÃ£o precisa treinar sempre)

---

## ðŸ”§ MÃ©todos de ExportaÃ§Ã£o em Python

### 1. **Pickle** (MÃ©todo PadrÃ£o Python)

```python
import pickle

# Salvar modelo
with open('modelo.pkl', 'wb') as f:
    pickle.dump(modelo_treinado, f)

# Carregar modelo
with open('modelo.pkl', 'rb') as f:
    modelo_carregado = pickle.load(f)
```

**PrÃ³s:**

- Nativo do Python (biblioteca padrÃ£o)
- Funciona com qualquer objeto Python
- Simples de usar

**Contras:**

- NÃ£o Ã© seguro (pode executar cÃ³digo malicioso)
- NÃ£o Ã© compatÃ­vel entre versÃµes Python diferentes
- NÃ£o funciona em outras linguagens

---

### 2. **Joblib** (Otimizado para NumPy/scikit-learn)

```python
import joblib

# Salvar modelo
joblib.dump(modelo_treinado, 'modelo.joblib')

# Carregar modelo
modelo_carregado = joblib.load('modelo.joblib')
```

**PrÃ³s:**

- Mais eficiente que pickle para arrays NumPy grandes
- Recomendado pela documentaÃ§Ã£o do scikit-learn
- CompressÃ£o automÃ¡tica

**Contras:**

- Mesmas limitaÃ§Ãµes de seguranÃ§a do pickle

---

### 3. **ONNX** (Formato Universal)

```python
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

# Definir tipo de entrada
initial_type = [('float_input', FloatTensorType([None, 8]))]

# Converter para ONNX
onnx_model = convert_sklearn(modelo_treinado, initial_types=initial_type)

# Salvar
with open('modelo.onnx', 'wb') as f:
    f.write(onnx_model.SerializeToString())
```

**PrÃ³s:**

- Formato universal (funciona em C++, Java, JavaScript, etc.)
- Otimizado para produÃ§Ã£o
- Suporte a hardware especializado (GPU, TPU)

**Contras:**

- Mais complexo
- Nem todos os modelos sÃ£o suportados

---

## ðŸŽ¯ Processo Completo no HubFÃ³lio

### Passo 1: Treinar Modelo no Notebook

```python
from sklearn.linear_model import LinearRegression

# Treinar modelo
model = LinearRegression()
model.fit(X_train, y_train)

# Avaliar
score = model.score(X_test, y_test)
print(f"RÂ² Score: {score:.4f}")
```

### Passo 2: Exportar como .pkl

```python
import pickle
import os

# Criar diretÃ³rio para modelos
os.makedirs('models', exist_ok=True)

# Salvar modelo
model_path = 'models/hubfolio_model.pkl'
with open(model_path, 'wb') as f:
    pickle.dump(model, f)

print(f"âœ… Modelo salvo em: {model_path}")
print(f"   Tamanho: {os.path.getsize(model_path)} bytes")
```

### Passo 3: Testar Carregamento

```python
# Carregar modelo do disco
with open(model_path, 'rb') as f:
    modelo_carregado = pickle.load(f)

# Testar prediÃ§Ã£o
exemplo = [[3, 10, 4, 3, 4, 80, 1, 1]]  # valores de exemplo
predicao = modelo_carregado.predict(exemplo)
print(f"PrediÃ§Ã£o: {predicao[0]:.2f}")
```

### Passo 4: Upload para API FastAPI

**OpÃ§Ã£o A - Via curl/PowerShell:**

```powershell
# PowerShell
$headers = @{
    "Content-Type" = "multipart/form-data"
}
Invoke-WebRequest -Uri http://localhost:8001/model/upload `
    -Method POST `
    -InFile "models\hubfolio_model.pkl"
```

**OpÃ§Ã£o B - Via Swagger UI:**

1. Acesse http://localhost:8001/docs
2. Encontre o endpoint `POST /model/upload`
3. Clique em "Try it out"
4. FaÃ§a upload do arquivo `hubfolio_model.pkl`
5. Execute

**OpÃ§Ã£o C - Via Python (requests):**

```python
import requests

url = "http://localhost:8001/model/upload"
files = {'file': open('models/hubfolio_model.pkl', 'rb')}
response = requests.post(url, files=files)
print(response.json())
```

---

## ðŸ§ª ValidaÃ§Ã£o PÃ³s-Upload

### Verificar se modelo foi carregado:

```powershell
Invoke-WebRequest -Uri http://localhost:8001/model/info
```

**Resposta esperada:**

```json
{
  "model_loaded": true,
  "model_type": "LinearRegression",
  "model_path": "/app/models/hubfolio_model.pkl",
  "features_expected": 8
}
```

### Testar prediÃ§Ã£o:

```powershell
$body = @{
    projetos_min = 3
    habilidades_min = 10
    kw_contexto = 4
    kw_processo = 3
    kw_resultado = 4
    consistencia_visual_score = 80
    bio = 1
    contatos = 1
} | ConvertTo-Json

Invoke-WebRequest -Uri http://localhost:8001/predict `
    -Method POST `
    -ContentType "application/json" `
    -Body $body
```

---

## ðŸ“‹ Checklist Completo

- [ ] Ambiente virtual criado (`python -m venv venv`)
- [ ] DependÃªncias instaladas (`pip install -r requirements-notebook.txt`)
- [ ] Notebook aberto no Jupyter
- [ ] Dados carregados (150 registros)
- [ ] Modelos treinados (Linear Regression, Decision Tree, KNN)
- [ ] Melhor modelo selecionado
- [ ] Modelo exportado como `.pkl`
- [ ] Teste de carregamento executado
- [ ] Modelo enviado para API
- [ ] Endpoint `/model/info` retorna sucesso
- [ ] PrediÃ§Ã£o teste executada com sucesso

---

## âš ï¸ Boas PrÃ¡ticas

### 1. **Salvar Metadados Junto com o Modelo**

```python
import pickle

modelo_completo = {
    'model': modelo_treinado,
    'features': ['projetos_min', 'habilidades_min', ...],
    'metrics': {
        'r2_score': 0.85,
        'rmse': 12.5,
        'mae': 9.2
    },
    'training_date': '2025-11-25',
    'training_samples': 150
}

with open('models/hubfolio_model_v1.pkl', 'wb') as f:
    pickle.dump(modelo_completo, f)
```

### 2. **Versionamento**

```
models/
â”œâ”€â”€ hubfolio_model_v1.0.pkl  # Baseline (Linear Regression)
â”œâ”€â”€ hubfolio_model_v1.1.pkl  # Decision Tree
â”œâ”€â”€ hubfolio_model_v2.0.pkl  # Ensemble
â””â”€â”€ production/
    â””â”€â”€ hubfolio_model.pkl    # Modelo em produÃ§Ã£o
```

### 3. **ValidaÃ§Ã£o PrÃ©-Deploy**

```python
# Antes de fazer upload, valide o modelo
def validar_modelo(modelo, X_test, y_test):
    """Valida modelo antes de deploy"""

    # 1. Verificar tipo
    assert hasattr(modelo, 'predict'), "Modelo nÃ£o tem mÃ©todo predict()"

    # 2. Testar prediÃ§Ã£o
    y_pred = modelo.predict(X_test)
    assert len(y_pred) == len(y_test), "Tamanho de prediÃ§Ã£o incorreto"

    # 3. Verificar range
    assert y_pred.min() >= 0 and y_pred.max() <= 100, "IQ fora do range 0-100"

    print("âœ… Modelo validado com sucesso!")
    return True

validar_modelo(modelo_final, X_test, y_test)
```

---

## ðŸŽ“ Resumo

**Pickle vs Joblib:**

- Use **Pickle** para modelos pequenos e simples
- Use **Joblib** para modelos grandes com arrays NumPy

**Para o HubFÃ³lio:**

- Modelo LinearRegression Ã© pequeno â†’ **Pickle Ã© suficiente**
- 8 features, 150 amostras â†’ Arquivo ~5-20 KB

**Fluxo Recomendado:**

1. Treinar no Jupyter Notebook
2. Exportar com Pickle
3. Testar localmente
4. Upload via Swagger UI
5. Validar via `/model/info`
6. Testar prediÃ§Ã£o
